# Copyright (c) 2013-2018 Snowplow Analytics Ltd. All rights reserved.
#
# This program is licensed to you under the Apache License Version 2.0, and
# you may not use this file except in compliance with the Apache License
# Version 2.0.  You may obtain a copy of the Apache License Version 2.0 at
# http://www.apache.org/licenses/LICENSE-2.0.
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the Apache License Version 2.0 is distributed on an "AS
# IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.  See the Apache License Version 2.0 for the specific language
# governing permissions and limitations there under.

# This file (application.conf.example) contains a template with
# configuration options for the Scala Stream Collector.
#
# To use, copy this to 'application.conf' and modify the configuration options.

# 'collector' contains configuration options for the main Scala collector.
collector {
  interface = "0.0.0.0"
  port = 8080

  p3p {
    policyRef = "/w3c/p3p.xml"
    CP = "NOI DSP COR NID PSA OUR IND COM NAV STA"
  }

  crossDomain {
    enabled = false
    domains = ["*"]
    secure = true
  }

  cookie {
    enabled = true
    expiration = "365 days" # e.g. "365 days"
    name = sp
    domain = ""
    secure = false
    httpOnly = false
    sameSite = None
  }

  cookieBounce {
    enabled = false
    name = "n3pc"
    fallbackNetworkUserId = "00000000-0000-4000-A000-000000000000"
  }

  cors {
    accessControlMaxAge = "5m"
  }

  paths {
    "/tK9x1Vx6a67KU/zR9fAO7H7niI2" = "/com.snowplowanalytics.snowplow/tp2"
  }

  doNotTrackCookie {
    enabled = false
    name = cookie-name
    value = ""
  }

  redirectMacro {
    enabled = false
    placeholder = "[TOKEN]"
  }

  rootResponse {
    enabled = false
    statusCode = 200
    body = "ok"
  }

  streams {
    good = RawEvents
    bad = BadRawEvents
    useIpAddressAsPartitionKey = false

    sink {
      enabled = nsq
      host = nsqd
      port = 4150
    }

    buffer {
      byteLimit = 4000000
      recordLimit = 500 # Not supported by Kafka; will be ignored
      timeLimit = 5000
    }
  }

  prometheusMetrics {
    enabled = false
    durationBuckets = [0.1, 3, 10]
  }
}

akka {
  loglevel = DEBUG # 'OFF' for no logging, 'DEBUG' for all logging.
  loggers = ["akka.event.slf4j.Slf4jLogger"]

  http.server {
    remote-address-header = on
    raw-request-uri-header = on
    parsing {
      max-uri-length = 32768
      uri-parsing-mode = relaxed
    }
  }
}
